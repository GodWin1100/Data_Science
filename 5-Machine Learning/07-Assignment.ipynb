{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Assignment-07\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is the definition of a target function? In the sense of a real-life example, express the target function. How is a target function's fitness assessed?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A target function, in machine learning, is a method for solving a problem that an AI algorithm parses its training data to find.\n",
    "- Once an algorithm finds its target function, that function can be used to predict results (predictive analysis).\n",
    "- The target function is essentially the formula that an algorithm feeds data to in order to calculate predictions.\n",
    "- The target function can only be inferred in a Supervised learning task.\n",
    "- A target function maps data to its target value such as if you have picture of a digit, the function then receives that picture as the input and spit the digit value as the output.\n",
    "- The observations of inherent rules about how the studied subject operates inform the AI on how to process future data that does not include an output by applying this previously unknown function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. What are predictive models, and how do they work? What are descriptive types, and how do you use them? Examples of both types of models should be provided. Distinguish between these two forms of models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Predictive modeling is a statistical technique using machine learning and data mining to predict and forecast likely future outcomes with the aid of historical and existing data.\n",
    "- It works by analyzing current and historical data and projecting what it learns on a model generated to forecast likely outcomes.\n",
    "- A descriptive model is used for tasks that would benefit from the insight gained from summarizing data in new and interesting ways.\n",
    "- The three main types of descriptive studies are **Case studies, Naturalistic observation, and Surveys**.\n",
    "- Predictive model is supervised learning while Descriptive model is unsupervised learning.\n",
    "- As opposed to predictive models that predict a target of interest, in a descriptive model, no single feature is more important than any other.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Describe the method of assessing a classification model's efficiency in detail. Describe the various measurement parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Classification model are assessed by comparing predicted classes and actual classes.\n",
    "- Various measurement to evaluate classification models are\n",
    "  - Classification Accuracy\n",
    "  - Confusion Matrix\n",
    "    - Precision\n",
    "    - Recall\n",
    "    - F1 Score\n",
    "    - Specificity\n",
    "    - AUC\n",
    "  - Binary Cross-Entropy\n",
    "  - Categorical Cross-Entropy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Answer the following\n",
    "\n",
    "1. In the sense of machine learning models, what is underfitting? What is the most common reason for underfitting?\n",
    "2. What does it mean to overfit? When is it going to happen?\n",
    "3. In the sense of model fitting, explain the bias-variance trade-off.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Underfitting is a scenario in data science where a data model is unable to capture the relationship between the input and output variables accurately, generating a high error rate on both the training set and unseen data.\n",
    "\n",
    "---\n",
    "\n",
    "- Overfitting happens when a model learns the detail and noise in the training data to the extent that it negatively impacts the performance of the model on new data.\n",
    "- This means that the noise or random fluctuations in the training data is picked up and learned as concepts by the model.\n",
    "\n",
    "---\n",
    "\n",
    "- The bias is known as the difference between the prediction of the values by the ML model and the actual value.\n",
    "- Being high in biasing gives a large error in training as well as testing data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Is it possible to boost the efficiency of a learning model? If so, please clarify how.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Building a machine learning model is not enough to get the right predictions, as you have to check the accuracy and need to validate the same to ensure get the precise results.\n",
    "- And validating the model will improve the performance of the ML model.\n",
    "- Efficiency can be improved slightly by training on optimal amount of data and using appropriate ML model algorithm.\n",
    "- Efficiency of model will depreciate as the time goes due to data drift.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. How would you rate an unsupervised learning model's success? What are the most common success indicators for an unsupervised learning model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Unsupervised learning model output cannot be compared because it does not has any target variable.\n",
    "- Evaluation of unsupervised learning is mainly subjective/domain based.\n",
    "- For eg. in clustering K-Means, to find appropriate no. of cluster we use WCSS but in case we want only specific n cluster based on the requirement.\n",
    "- Common measure:\n",
    "  - Silhouette coefficient\n",
    "  - Dunn Index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Is it possible to use a classification model for numerical data or a regression model for categorical data with a classification model? Explain your answer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Classification model could be used on numerical data as target where each data point will be one category itself and similarly for Regression model, categorical target variable will assume data point as numerical data.\n",
    "- In such cases model accuracy will be very poor and won't be able to predict accurately as it will be underfit model or overfit model only.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Describe the predictive modeling method for numerical values. What distinguishes it from categorical predictive modeling?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Predictive modeling is a statistical technique using machine learning and data mining to predict and forecast likely future outcomes with the aid of historical and existing data.\n",
    "- It works by analyzing current and historical data and projecting what it learns on a model generated to forecast likely outcomes.\n",
    "- Classification is the process of identifying the category or class label of the new observation to which it belongs.\n",
    "- Predication is the process of identifying the missing or unavailable numerical data for a new observation.\n",
    "- That is the key difference between classification and prediction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. The following data were collected when using a classification model to predict the malignancy of a group of patients' tumors. Based on data determine the model's error rate, Kappa value, sensitivity, precision, and F-measure.\n",
    "\n",
    "- Accurate estimates – 15 cancerous, 75 benign\n",
    "- Wrong predictions – 3 cancerous, 7 benign\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1 is cancerous, 0 is benign\n",
    "- Error: 0.099\n",
    "- Kappa: 0.688\n",
    "- Sensitivity(Recall): 0.83\n",
    "- Precision: 0.681\n",
    "- F-measure(F1 score): 0.74\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.94        82\n",
      "           1       0.68      0.83      0.75        18\n",
      "\n",
      "    accuracy                           0.90       100\n",
      "   macro avg       0.82      0.87      0.84       100\n",
      "weighted avg       0.91      0.90      0.90       100\n",
      "\n",
      "0.6882793017456359\n",
      "0.09999999999999998\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    cohen_kappa_score,\n",
    "    classification_report,\n",
    "    zero_one_loss,\n",
    "    precision_score,\n",
    "    f1_score,\n",
    "    recall_score,\n",
    ")\n",
    "\n",
    "actual = [1] * 18 + [0] * 82\n",
    "predict = [1] * 15 + [0] * 78 + [1] * 7\n",
    "print(classification_report(actual, predict))\n",
    "print(cohen_kappa_score(actual, predict))\n",
    "print(zero_one_loss(actual, predict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Make quick notes on:\n",
    "\n",
    "1. The process of holding out\n",
    "2. Cross-validation by tenfold\n",
    "3. Adjusting the parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **The process of holding out:**\n",
    "\n",
    "  - The hold-out method for training machine learning model is the process of splitting the data in different splits and using one split for training the model and other splits for validating and testing the models.\n",
    "  - The hold-out method is used for both model evaluation and model selection.\n",
    "\n",
    "---\n",
    "\n",
    "- **Cross-validation by tenfold:**\n",
    "\n",
    "  - 10-fold cross validation would perform the fitting procedure a total of ten times, with each fit being performed on a training set consisting of 90% of the total training set selected at random, with the remaining 10% used as a hold out set for validation.\n",
    "\n",
    "---\n",
    "\n",
    "- **Adjusting the parameters:**\n",
    "  - A fancy name for training: the selection of parameter values, which are optimal in some desired sense (eg. minimize an objective function you choose over a dataset you choose).\n",
    "  - The parameters are the weights and biases of the network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Define the following terms:\n",
    "\n",
    "1. Purity vs. Silhouette width\n",
    "2. Boosting vs. Bagging\n",
    "3. The eager learner vs. the lazy learner\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Purity vs Silhouette width:**\n",
    "  - Purity is a measure of the extent to which clusters contain a single class.\n",
    "  - Its calculation can be thought of as follows: For each cluster, count the number of data points from the most common class in said cluster.\n",
    "  - The silhouette width is also an estimate of the average distance between clusters.\n",
    "  - Its value is comprised between 1 and -1 with a value of 1 indicating a very good cluster.\n",
    "\n",
    "---\n",
    "\n",
    "- **Boosting vs. Bagging:**\n",
    "  - Bagging is a way to decrease the variance in the prediction by generating additional data for training from dataset using combinations with repetitions to produce multi-sets of the original data.\n",
    "  - Boosting is an iterative technique which adjusts the weight of an observation based on the last classification.\n",
    "\n",
    "---\n",
    "\n",
    "- **The eager learner vs. the lazy learner:**\n",
    "  - A lazy learner delays abstracting from the data until it is asked to make a prediction.\n",
    "  - An eager learner abstracts away from the data during training and uses this abstraction to make predictions rather than directly compare queries with instances in the dataset.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('fsds')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "20f5f825ba7e1e0138bea706cf7ce76ba178632e6be331b5251920b13e58ac94"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
