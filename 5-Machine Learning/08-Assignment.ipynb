{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Assignment-08\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What exactly is a feature? Give an example to illustrate your point.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Features are the basic building blocks of datasets.\n",
    "- The quality of the features in your dataset has a major impact on the quality of the insights you will gain when you use that dataset for machine learning.\n",
    "- Additionally, different business problems within the same industry do not necessarily require the same features, which is why it is important to have a strong understanding of the business goals of your data science project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. What are the various circumstances in which feature construction is required?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Feature construction is a process which builds intermediate features from the original descriptors in a dataset.\n",
    "- The aim is to build more efficient features for a machine data mining task.\n",
    "- The features in your data will directly influence the predictive models you use and the results you can achieve.\n",
    "- Better features means flexibility.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Describe how nominal variables are encoded.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nominal data is made of discrete values with no numerical relationship between the different categories — mean and median are meaningless. Animal species is one example.\n",
    "- It can be collectively grouped on the basis of a particular characteristic—a qualitative property.\n",
    "- They can be encoded by One Hot Encoding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Describe how numeric features are converted to categorical features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Numeric Feature with continuous/discrete number can be binned/grouped based on specific characteristic and can be transformed to categorical feature.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Describe the feature selection wrapper approach. State the advantages and disadvantages of this approach?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Wrapper methods measure the “usefulness” of features based on the ML algorithm.\n",
    "- It is computationally expensive and has high chance of over-fitting.\n",
    "- Assure that most useful feature are selected.\n",
    "- eg. Forward Selection, Backward elimination, Stepwise selection, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. When is a feature considered irrelevant? What can be said to quantify it?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Features are considered relevant if they are either strongly or weakly relevant, and are considered irrelevant otherwise.\n",
    "- Irrelevant features can never contribute to prediction accuracy, by definition.\n",
    "- Also to quantify it we need to first check the list of features, There are three types of feature selection:\n",
    "  - **Wrapper methods** (forward, backward, and stepwise selection)\n",
    "  - **Filter methods** (ANOVA, Pearson correlation, variance thresholding)\n",
    "  - **Embedded methods** (Lasso, Ridge, Decision Tree).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. When is a function considered redundant? What criteria are used to identify features that could be redundant?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If two features `{X1, X2}` are highly correlated, then the two features become redundant features since they have same information in terms of correlation measure.\n",
    "- In other words, the correlation measure provides statistical association between any given a pair of features.\n",
    "- Minimum redundancy feature selection algorithm can be used to keep the redundant feature out.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. What are the various distance measurements used to determine feature similarity?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Four of the most commonly used distance measures in machine learning are as follows:\n",
    "  - Manhattan Distance.\n",
    "  - Euclidean Distance.\n",
    "  - Cosine Distance\n",
    "  - Hamming Distance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. State difference between Euclidean and Manhattan distances?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Euclidean distance is extensively applied in analysis of convolutional codes and Trellis codes.\n",
    "- Euclidean distance is the shortest path between source and destination which is a straight line.\n",
    "- Manhattan distance is sum of all the real distances between source(s) and destination(d) and each distance are always the straight lines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Distinguish between feature transformation and feature selection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Feature selection is for filtering irrelevant or redundant features from your dataset.\n",
    "- Feature transformation is a mathematical transformation in which we apply a mathematical formula to a particular column(feature) and transform the values which are useful for our further analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Make brief notes on any two of the following:\n",
    "\n",
    "1. SVD (Standard Variable Diameter Diameter)\n",
    "2. Collection of features using a hybrid approach\n",
    "3. The width of the silhouette\n",
    "4. Receiver operating characteristic curve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **The width of the silhouette**\n",
    "  - Silhouette width is defined as: Let i be a focal object belonging to cluster A. Denote by C a cluster not containing i. a(i) is defined as the average dissimilarity between i and all other objects in A, while c(i,C) is the average dissimilarity between i and all objects in C.\n",
    "  - Silhouette width s(i) ranges between -1 and 1.\n",
    "  - Values near 1 indicate that object i is much closer to the other objects in the same cluster than to objects of the closest other cluster, implying a correct classification.\n",
    "  - If s(i) is near 0, the correct classification of the focal object is doubtful, thus suggesting intermediate position between two clusters.\n",
    "  - s(i) near −1 indicates obvious misclassification.\n",
    "  - For a cluster containing a single object, s(i) takes the arbitrary value 0.\n",
    "\n",
    "---\n",
    "\n",
    "- **Receiver Operating Characteristic (ROC) Curve**\n",
    "  - A receiver operating characteristic curve, or ROC curve, is a graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied.\n",
    "  - This curve plots two parameters:\n",
    "    - True Positive Rate\n",
    "    - False Positive Rate\n",
    "  - An ROC curve plots TPR vs. FPR at different classification thresholds.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2e4a015a5e8b3d416719d76fc156fe7e163a5f8678adc2f1ead049a4ae2a6091"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
