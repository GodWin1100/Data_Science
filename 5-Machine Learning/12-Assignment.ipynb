{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Assignment-12\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is prior probability? Give an example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prior probability is the probability of an event before new data is collected.\n",
    "- This is the best rational assessment of the probability of an outcome based on the current knowledge before an experiment is performed.\n",
    "- For example, three acres of land have the labels A, B, and C. One acre has reserves of oil below its surface, while the other two do not.\n",
    "- The prior probability of oil being found on acre C is one third, or 0.333.\n",
    "- But if a drilling test is conducted on acre B, and the results indicate that no oil is present at the location, then the posterior probability of oil being found on acres A and C become 0.5, as each acre has one out of two chances.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. What is posterior probability? Give an example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A posterior probability is the revised or updated probability of an event occurring after taking into consideration new information.\n",
    "- The posterior probability is calculated by updating the prior probability using Bayes' theorem.\n",
    "- For example, let there be two urns, urn A having 5 black balls and 10 red balls and urn B having 10 black balls and 5 red balls.\n",
    "- Now if an urn is selected at random, the probability that urn A is chosen is 0.5.\n",
    "- This is the a priori probability.\n",
    "- If we are given an additional piece of information that a ball was drawn at random from the selected urn, and that ball was black, what is the probability that the chosen urn is urn A?\n",
    "- Posterior probability takes into account this additional information and revises the probability downward from 0.5 to 0.333 according to Bayes´ theorem, because a black ball is more probable from urn B than urn A.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. What is likelihood probability? Give an example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The term \"probability\" refers to the possibility of something happening.\n",
    "- The term Likelihood refers to the process of determining the best data distribution given a specific situation in the data.\n",
    "- The likelihood term, $P(Y|X)$ is the probability of getting a result for a given value of the parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. What is Naïve Bayes classifier? Why is it named so?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Naive Bayes is a simple and powerful algorithm for predictive modeling.\n",
    "- Naive Bayes is called naive because it assumes that each input variable is independent.\n",
    "- This is a strong assumption and unrealistic for real data; however, the technique is very effective on a large range of complex problems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. What is optimal Bayes classifier?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The Bayes Optimal Classifier is a probabilistic model that makes the most probable prediction for a new example.\n",
    "- It finds the most probable prediction using the training data and space of hypotheses to make a prediction for a new data instance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Write any two features of Bayesian learning methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This provides a more flexible approach to learning than algorithms that completely eliminate a hypothesis if it is found to be inconsistent with any single example.\n",
    "- A probability distribution over observed data for each possible hypothesis.\n",
    "- New instances can be classified by combining the predictions of multiple hypotheses, weighted by their probabilities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Define the concept of consistent learners.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A learner $L$ using a hypothesis $H$ and training data $D$ is said to be a consistent learner if it always outputs a hypothesis with zero error on $D$ whenever $H$ contains such a hypothesis.\n",
    "- By definition, a consistent learner must produce a hypothesis in the version space for $H$ given $D$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Write any two strengths of Bayes classifier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Naive Bayes algorithm works quickly and can save a lot of time.\n",
    "- It is suitable for solving multi-class prediction problems.\n",
    "- If its assumption of the independence of features holds true, it can perform better than other models and requires much less training data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Write any two weaknesses of Bayes classifier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The greatest weakness of the naïve Bayes classifier is that it relies on an often-faulty assumption of equally important and independent features which results in biased posterior probabilities.\n",
    "- It does not work well with other type of data except categorical.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Explain how Naïve Bayes classifier is used for\n",
    "\n",
    "    1. Text classification\n",
    "    2. Spam filtering\n",
    "    3. Market sentiment analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Text classification:**\n",
    "  - The Naive Bayes classifier is a simple classifier that classifies based on probabilities of events.\n",
    "  - It is the applied commonly to text classification.\n",
    "  - With the training set, we can train a Naive Bayes classifier which we can use to automatically categorize a new sentence.\n",
    "- **Spam filtering:**\n",
    "  - Naive Bayes classifiers work by correlating the use of tokens (typically words, or sometimes other things), with spam and non-spam e-mails and then using Bayes' theorem to calculate a probability that an email is or is not spam.\n",
    "  - It is one of the oldest ways of doing spam filtering, with roots in the 1990s.\n",
    "- **Market sentiment analysis:**\n",
    "  - Market Sentiment analysis is a field dedicated to extracting subjective emotions and feelings from text.\n",
    "  - One common use of sentiment analysis is to figure out if a text expresses negative or positive feelings.\n",
    "  - Naive Bayes is a popular algorithm for classifying text.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2e4a015a5e8b3d416719d76fc156fe7e163a5f8678adc2f1ead049a4ae2a6091"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
