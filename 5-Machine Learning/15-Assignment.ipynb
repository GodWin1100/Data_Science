{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Assignment-15\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Recognize the differences between supervised, semi-supervised, and unsupervised learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Supervised learning** aims to learn a function that, given a sample of data and desired outputs, approximates a function that maps inputs to outputs.\n",
    "\n",
    "- **Semi-supervised learning** aims to label unlabeled data points using knowledge learned from a small number of labeled data points.\n",
    "\n",
    "- **Unsupervised learning** does not have (or need) any labeled outputs, so its goal is to infer the natural structure present within a set of data points.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Describe in detail any five examples of classification problems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Customer behavior prediction:**\n",
    "  - Customers can be classified into different categories based on their buying patterns, web store browsing patterns etc.\n",
    "  - For example, classification models can be used to determine whether a customer is likely to purchase more items or not.\n",
    "  - If the classification model predicts a greater likelihood that they are about to make more purchases, then you might want to send them promotional offers and discounts accordingly.\n",
    "  - Or if it has been determined that they will probably fall off of their purchasing habits soon, maybe save them for later by making their information readily available.\n",
    "- **Document classification:**\n",
    "  - A multinomial classification model can be trained to classify documents in different categories.\n",
    "  - In this case, the classification model can be thought of as a function that maps from a document to a category label.\n",
    "  - Different algorithms can be used for document classification such as Naive Bayes classifier, Support Vector Machines (SVM), or Neural Networks models.\n",
    "  - Deep learning algorithms such as Deep Boltzmann Machines (DBMs), Deep Belief Networks (DBNs), and Stacked Autoencoders (SAEs) give state-of-the-art classification results on different document classification datasets.\n",
    "- **Spam filtering:**\n",
    "  - An algorithm is trained to recognize spam email by learning the characteristics of what constitutes spam vs non-spam email.\n",
    "  - The classification model could be a function that maps from an email text to a spam classification (or non-spam classification).\n",
    "  - Algorithms such as Naive Bayes and Support Vector Machines can be used for classification.\n",
    "  - Once the classification model is trained, it can then be used to filter new incoming emails as spam or non-spam.\n",
    "  - The picture below represents the Spam classification model depicted as Spam classifier.\n",
    "- **Malware classification:**\n",
    "  - A multinomial classification can be used to classify the new/emerging-malware on the basis of comparable features of similar malware.\n",
    "  - Malware classification is very useful for security experts to take appropriate actions for combating/preventing malware.\n",
    "  - Machine learning classification algorithms such as Naïve Bayes, k-NN, and tree-based models can be used for malware classification.\n",
    "- **Credit card fraud detection:**\n",
    "  - A binary classification model can be used for credit card fraud detection where the historical transaction data of a customer is analyzed using machine learning algorithms like Naïve Bayes, k-NN, etc.\n",
    "  - Based on past fraudulent or non-fraudulent transaction data and machine learning classification models, it can be predicted whether the given credit card will result in fraudulent transactions or not.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Describe each phase of the classification process in detail.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Define the Objectives of the Data Classification Process\n",
    "   - What are you looking for? Why?\n",
    "   - Which systems are in-scope for the initial classification phase?\n",
    "   - What compliance regulations apply to your organization?\n",
    "   - Are there other business objectives you want to tackle? (e.g., risk mitigation, storage optimization, analytics)\n",
    "2. Categorize Data Types\n",
    "   - Identify what kinds of data the organization creates (e.g., customer lists, financial records, source code, product plans)\n",
    "   - Delineate proprietary data vs. public data\n",
    "   - Do you expect to find GDPR, CCPA, or other regulated data?\n",
    "3. Establish Classification Levels\n",
    "   - How many classification levels do you need?\n",
    "   - Document each level and provide examples\n",
    "   - Train users to classify data (if manual classification is planned)\n",
    "4. Define the Automated Classification Process\n",
    "   - Define how to prioritize which data to scan first (e.g., prioritize active over stale, open over protected)\n",
    "   - Establish the frequency and resources you will dedicate to automated data classification\n",
    "5. Define the Categories and Classification Criteria\n",
    "   - Define your high-level categories and provide examples (e.g., PII, PHI)\n",
    "   - Define or enable applicable classification patterns and labels\n",
    "   - Establish a process to review and validate both user classified and automated results\n",
    "6. Define Outcomes and Usage of Classified Data\n",
    "   - Document risk mitigation steps and automated policies (e.g., move or archive PHI if unused for 180 days, automatically remove global access groups from folders with sensitive data)\n",
    "   - Define a process to apply analytics to classification results\n",
    "   - Establish expected outcomes from the analytic analysis\n",
    "7. Monitor and Maintain\n",
    "   - Establish an ongoing workflow to classify new or updated data\n",
    "   - Review the classification process and update if necessary due to changes in business or new regulations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Go through the SVM model in depth using various scenarios.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Support Vector Machine (SVM)** is a supervised machine learning algorithm that can be used for both classification or regression challenges.\n",
    "- Support Vectors are simply the coordinates of individual observation.\n",
    "- The SVM classifier is a frontier that best segregates the two classes (hyper-plane/ line).\n",
    "- The idea of SVM is simple: The algorithm creates a line or a hyperplane which separates the data into classes.\n",
    "- It can solve linear and non-linear problems and work well for many practical problems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. What are some of the benefits and drawbacks of SVM?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Benefits:**\n",
    "  - SVM works relatively well when there is a clear margin of separation between classes.\n",
    "  - SVM is more effective in high dimensional spaces.\n",
    "  - SVM is effective in cases where the number of dimensions is greater than the number of samples.\n",
    "  - SVM is relatively memory efficient.\n",
    "- **Drawbacks:**\n",
    "  - SVM algorithm is not suitable for large data sets.\n",
    "  - SVM does not perform very well when the data set has more noise i.e. target classes are overlapping.\n",
    "  - In cases where the number of features for each data point exceeds the number of training data samples,the SVM will underperform.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Go over the kNN model in depth.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The abbreviation KNN stands for **K-Nearest Neighbour**.\n",
    "- The number of nearest neighbours to a new unknown variable that has to be predicted or classified is denoted by the symbol 'K'.\n",
    "- **kNN** is the simplest machine learning algorithm to understand and also to explain.\n",
    "- It is a supervised machine learning algorithm.\n",
    "- It is a versatile algorithm i.e. useful for both classification and regression.\n",
    "- It has one big advantage is that kNN ha no pre assumption about the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Discuss the kNN algorithm's error rate and validation error.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Training error here is the error you'll have when you input your training set to your KNN as test set.\n",
    "- Since your test sample is in the training dataset, it'll choose itself as the closest and never make mistake.\n",
    "- For this reason, the training error will be zero when K = 1, irrespective of the dataset.\n",
    "- kNN produces predictions by looking at the k nearest neighbours of a case x to predict its y, so that's fine.\n",
    "- In particular, the kNN model basically consists of its training cases - but that's the cross validation procedure doesn't care about at all.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. For kNN, talk about how to measure the difference between the test and training results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- KNN can be used for classification — the output is a class membership (predicts a class — a discrete value).\n",
    "- An object is classified by a majority vote of its neighbors, with the object being assigned to the class most common among its k nearest neighbors.\n",
    "- KNN classifier does not have any specialized training phase as it uses all the training samples for classification and simply stores the results in memory.\n",
    "- KNN is a non-parametric algorithm because it does not assume anything about the training data.\n",
    "- kNN can only be tuned based on K value and it does not train rather does simple comparison.\n",
    "- Difference can be checked with the amount of correctly classified and misclassified data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Create the kNN algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Select the number K of the neighbors\n",
    "2. Calculate the Euclidean distance of K number of neighbors\n",
    "3. Take the K nearest neighbors as per the calculated Euclidean distance.\n",
    "4. Among these k neighbors, count the number of the data points in each category.\n",
    "5. Assign the new data points to that category for which the number of the neighbor is maximum.\n",
    "6. Our model is ready.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. What is a decision tree, exactly? What are the various kinds of nodes? Explain all in depth.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A decision tree is a tree-like model that acts as a decision support tool, visually displaying decisions and their potential outcomes, consequences, and costs.\n",
    "- Drawing a decision tree diagram starts from left to right and consists of burst nodes that split into different paths.\n",
    "- There are three different types of nodes: chance nodes, decision nodes, and end nodes.\n",
    "  - A chance node, shows the probabilities of certain results.\n",
    "  - A decision node,shows a decision to be made, and\n",
    "  - An end node shows the final outcome of a decision path.\n",
    "- The Decision Tree consists of the following different types of nodes:\n",
    "  - **Root node:** It is the top-most node of the Tree from where the Tree starts.\n",
    "  - **Decision nodes:** One or more Decision nodes that result in the splitting of data into multiple data segments and our main goal is to have the children nodes with maximum homogeneity or purity.\n",
    "  - **Leaf nodes:** These nodes represent the data section having the highest homogeneity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Describe the different ways to scan a decision tree.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- “Greedy Approach is based on the concept of Heuristic Problem Solving by making an optimal local choice at each node. By making these local optimal choices, we reach the approximate optimal solution globally.”\n",
    "- The algorithm can be summarized as :\n",
    "  1. At each stage (node), pick out the best feature as the test condition.\n",
    "  2. Now split the node into the possible outcomes (internal nodes).\n",
    "  3. Repeat the above steps till all the test conditions have been exhausted into leaf nodes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Describe in depth the decision tree algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A decision tree is a map of the possible outcomes of a series of related choices.\n",
    "- It allows an individual or organization to weigh possible actions against one another based on their costs, probabilities, and benefits.\n",
    "- As the name goes, it uses a tree-like model of decisions.\n",
    "- They can be used either to drive informal discussion or to map out an algorithm that predicts the best choice mathematically.\n",
    "- A decision tree typically starts with a single node, which branches into possible outcomes.\n",
    "- Each of those outcomes leads to additional nodes, which branch off into other possibilities.\n",
    "- A general algorithm for a decision tree can be described as follows:\n",
    "  - Pick the best attribute/feature. The best attribute is one which best splits or separates the data.\n",
    "  - Ask the relevant question.\n",
    "  - Follow the answer path.\n",
    "  - Go to step 1 until you arrive to the answer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. In a decision tree, what is inductive bias? What would you do to stop overfitting?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The inductive bias (also known as learning bias) of a learning algorithm is the set of assumptions that the learner uses to predict outputs of given inputs that it has not encountered.\n",
    "- The kind of necessary assumptions about the nature of the target function are subsumed in the phrase inductive bias.\n",
    "- Overfitting makes the model relevant to its data set only, and irrelevant to any other data sets.\n",
    "- Some of the methods used to prevent overfitting include ensembling, data augmentation, data simplification, and cross-validation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Explain advantages and disadvantages of using a decision tree?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Advantage\n",
    "  - It is simple to understand as it follows the same process which a human follow while making any decision in real-life.\n",
    "  - It can be very useful for solving decision-related problems.\n",
    "  - It helps to think about all the possible outcomes for a problem.\n",
    "  - There is less requirement of data cleaning compared to other algorithms.\n",
    "- Disadvantage\n",
    "  - The decision tree contains lots of layers, which makes it complex.\n",
    "  - It may have an overfitting issue, which can be resolved using the Random Forest algorithm.\n",
    "  - For more class labels, the computational complexity of the decision tree may increase.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Describe in depth the problems that are suitable for decision tree learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Instances are represented by attribute-value pairs.\n",
    "  - Instances are described by a fixed set of attributes (e.g., Temperature) and their values (e.g., Hot).\n",
    "  - The easiest situation for decision tree learning is when each attribute takes on a small number of disjoint possible values (e.g., Hot, Mild, Cold).\n",
    "  - However, extensions to the basic algorithm allow handling real-valued attributes as well (e.g., representing Temperature numerically).”\n",
    "- The training data may contain errors.\n",
    "  - Decision tree learning methods are robust to errors, both errors in classifications of the training examples and errors in the attribute values that describe these examples.”\n",
    "- The training data may contain missing attribute values.\n",
    "  - Decision tree methods can be used even when some training examples have unknown values (e.g., if the Humidity of the day is known for only some of the training examples).”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Describe in depth the random forest model. What distinguishes a random forest?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The random forest is a classification algorithm consisting of many decisions trees.\n",
    "- It uses bagging and feature randomness when building each individual tree to try to create an uncorrelated forest of trees whose prediction by committee is more accurate than that of any individual tree.\n",
    "- The fundamental difference is that in Random forests, only a subset of features are selected at random out of the total and the best split feature from the subset is used to split each node in a tree, unlike in bagging where all features are considered for splitting a node.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. In a random forest, talk about OOB error and variable value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The out-of-bag (OOB) error is the average error for each calculated using predictions from the trees that do not contain in their respective bootstrap sample.\n",
    "- There are two measures of importance given for each variable in the random forest.\n",
    "- The first measure is based on how much the accuracy decreases when the variable is excluded.\n",
    "- The second measure is based on the decrease of Gini impurity when a variable is chosen to split a node.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2e4a015a5e8b3d416719d76fc156fe7e163a5f8678adc2f1ead049a4ae2a6091"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
