{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Assignment-16\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. In a linear equation, what is the difference between a dependent variable and an independent variable?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The independent variable is the cause.\n",
    "- Its value is independent of other variables in your study.\n",
    "- The dependent variable is the effect.\n",
    "- Its value depends on changes in the independent variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. What is the concept of simple linear regression? Give a specific example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Simple linear regression is a regression model that estimates the relationship between one independent variable and one dependent variable using a straight line.\n",
    "- Equation: $Y_i=\\beta_0 + \\beta_1X_i + \\epsilon$\n",
    "- Both variables should be quantitative.\n",
    "- Linear regression most often uses mean-square error (MSE) to calculate the error of the model.\n",
    "- For example, suppose that height was the only determinant of body weight.In this example, if an individual was 70 inches tall, we would predict his weight to be: Weight = 80 + 2 x (70) = 220 lbs.\n",
    "- In this simple linear regression, we are examining the impact of one independent variable on the outcome.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. In a linear regression, define the slope.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The slope of a regression line (b) represents the rate of change in Y as X changes.\n",
    "- It tells us how the dependent variable (y) changes for every one unit increase in the independent (x) variable, on average.\n",
    "- Because Y is dependent on X, the slope describes the predicted values of Y given X.\n",
    "- The slope must be calculated before the y-intercept when using a linear regression, as the intercept is calculated using the slope.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Determine the graph's slope, where the lower point on the line is represented as (3, 2) and the higher point is represented as (2, 2).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Slope $= \\frac{y_2-y_1}{x_2-x_1} = \\frac{2-2}{3-2} =0$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. In linear regression, what are the conditions for a positive slope?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Increase in X, increases the Y and the plotted line ascends from left to right.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. In linear regression, what are the conditions for a negative slope?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If the graph of the line falls from left to right the slope is negative.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. What is multiple linear regression and how does it work?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Multiple linear regression refers to a statistical technique that uses two or more independent variables to predict the outcome of a dependent variable.\n",
    "- The technique enables analysts to determine the variation of the model and the relative contribution of each independent variable in the total variance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. In multiple linear regression, define the number of squares due to error.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The mean squared error (MSE) tells you how close a regression line is to a set of points.\n",
    "- It does this by taking the distances from the points to the regression line (these distances are the “errors”) and squaring them.\n",
    "- It's called the mean squared error as you're finding the average of a set of errors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. In multiple linear regression, define the number of squares due to regression.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sum of squares is a statistical technique used in regression analysis to determine the dispersion of data points.\n",
    "- In a regression analysis, the goal is to determine how well a data series can be fitted to a function that might help to explain how the data series was generated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. In a regression equation, what is multicollinearity?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Multicollinearity occurs when two or more independent variables are highly correlated with one another in a regression model.\n",
    "- This means that an independent variable can be predicted from another independent variable in a regression model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. What is heteroskedasticity, and what does it mean?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Heteroskedasticity (also spelled heteroscedasticity) refers to the error variance, or dependence of scattering, within a minimum of one independent variable within a particular sample.\n",
    "- A common cause of variances outside the minimum requirement is often attributed to issues of data quality.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Describe the concept of ridge regression.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ridge Regression is a technique for analyzing multiple regression data that suffer from multicollinearity.\n",
    "- Ridge will reduce the impact of features that are not important in predicting your dependent values.\n",
    "- By adding a degree of bias to the regression estimates, ridge regression reduces the standard errors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Describe the concept of lasso regression.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- lasso (least absolute shrinkage and selection operator; also Lasso or LASSO) is a regression analysis method that performs both variable selection and regularization in order to enhance the prediction accuracy and interpretability of the resulting statistical model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. What is polynomial regression and how does it work?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Polynomial Regression is a form of Linear regression known as a special case of Multiple linear regression which estimates the relationship as an $n^{th}$ degree polynomial.\n",
    "- Polynomial Regression is sensitive to outliers so the presence of one or two outliers can also badly affect the performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Describe the basis function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A basis function is an element of a particular basis for a function space.\n",
    "- Every function in the function space can be represented as a linear combination of basis functions, just as every vector in a vector space can be represented as a linear combination of basis vectors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Describe how logistic regression works.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The logistic regression model computes a sum of the input features (in most cases, there is a bias term), and calculates the logistic of the result.\n",
    "- The output of logistic regression is always between (0, and 1), which is suitable for a binary classification task.\n",
    "- The higher the value, the higher the probability that the current sample is classified as class=1, and vice versa.\n",
    "- Formula: $\\phi(z)=\\frac{1}{1+e^{-z}}$\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2e4a015a5e8b3d416719d76fc156fe7e163a5f8678adc2f1ead049a4ae2a6091"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
